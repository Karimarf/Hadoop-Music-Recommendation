version: '3.8'

services:
  hadoop-namenode1:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode1
    ports:
      - "9870:9870"
      - "8020:8020"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - namenode1:/hadoop/dfs/name

  hadoop-namenode2:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode2
    ports:
      - "9871:9870"
      - "8021:8020"
    environment:
      - CLUSTER_NAME=hadoop-cluster
    volumes:
      - namenode2:/hadoop/dfs/name

  hadoop-datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode1
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode1:8020
      - HDFS_CONF_dfs_datanode_du_reserved=134217728
    volumes:
      - datanode1:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode1


  hadoop-datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode2
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode1:8020
      - HDFS_CONF_dfs_datanode_du_reserved=134217728
    volumes:
      - datanode2:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode1

  hadoop-datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode3
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode1:8020
      - HDFS_CONF_dfs_datanode_du_reserved=134217728
    volumes:
      - datanode3:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode2

  hadoop-datanode4:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode4
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode1:8020
      - HDFS_CONF_dfs_datanode_du_reserved=134217728
    volumes:
      - datanode4:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode2

  hadoop-datanode5:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode5
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode1:8020
      - HDFS_CONF_dfs_datanode_du_reserved=134217728
    volumes:
      - datanode5:/hadoop/dfs/data
    depends_on:
      - hadoop-namenode1

  spark-master:
    image: bde2020/spark-master:3.1.2-hadoop3.2
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    depends_on:
      - hadoop-namenode1

  spark-worker:
    image: bde2020/spark-worker:3.1.2-hadoop3.2
    container_name: spark-worker
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    depends_on:
      - spark-master

  pyspark-client:
    image: jupyter/all-spark-notebook
    container_name: pyspark-client
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - PYSPARK_PYTHON=python
    ports:
      - "8888:8888"  # Pour Jupyter
    volumes:
      - ./notebooks:/home/jovyan/work
    depends_on:
      - spark-master
      - hadoop-namenode1


volumes:
  namenode1:
  namenode2:
  datanode1:
  datanode2:
  datanode3:
  datanode4:
  datanode5:
